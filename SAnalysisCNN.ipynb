{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SAnalysisCNN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2So4H3o8yg4e","colab_type":"code","colab":{}},"source":["import torch\n","from torchtext import data\n","from torchtext import datasets\n","import random\n","\n","SEED = 1234\n","\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","TEXT = data.Field(tokenize='spacy')  #define how the review should be processed\n","LABEL = data.LabelField(dtype=torch.float) #used to process the sentiment\n","\n","train_data, test_data = datasets.IMDB.splits(TEXT, LABEL) #get dataset\n","\n","train_data, valid_data = train_data.split(random_state=random.seed(SEED))\n","#split trainset to train/valid\n","#pass the seed to get the same split each time"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VJ_7qez1jOkR","colab_type":"text"},"source":["# New Section"]},{"cell_type":"code","metadata":{"id":"XFhWGV4WzVLI","colab_type":"code","colab":{}},"source":["TEXT.build_vocab(train_data, max_size=25000, vectors=\"glove.6B.100d\")\n","LABEL.build_vocab(train_data)\n","#build vocab while keeping 25,000/100,000 most frequent words\n","#pass argument to download pre trained vectors"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g9m2mZhEzZu1","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 64\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #place tensors on GPU\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size=BATCH_SIZE, \n","    device=device)\n","\n","# create the iterators to go over in the test/validation step\n","# use bucket iterator which will batch similar length sentences to cut down on padding"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A1dbSdSwzveQ","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class CNN(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.convs = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(fs,embedding_dim)) for fs in filter_sizes])\n","        self.fc = nn.Linear(len(filter_sizes)*n_filters, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, x):\n","        \n","        #x = [sent len, batch size]\n","        \n","        x = x.permute(1, 0) #batch dim first to please CNN\n","                \n","        #x = [batch size, sent len]\n","        \n","        embedded = self.embedding(x)\n","                \n","        #embedded = [batch size, sent len, emb dim]\n","        \n","        embedded = embedded.unsqueeze(1) #to match channel =1\n","        \n","        #embedded = [batch size, 1, sent len, emb dim]\n","        \n","        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n","            \n","        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n","        \n","        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n","        \n","        #pooled_n = [batch size, n_filters]\n","        \n","        cat = self.dropout(torch.cat(pooled, dim=1)) #dropout on the concatenated filters output\n","\n","        #cat = [batch size, n_filters * len(filter_sizes)] *always the same size-number of filters\n","            \n","        return self.fc(cat)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ca5lnhG3zyav","colab_type":"code","colab":{}},"source":["INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","N_FILTERS = 100\n","FILTER_SIZES = [3,4,5]\n","OUTPUT_DIM = 1\n","DROPOUT = 0.5\n","\n","model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n","#create instance of the CNN class"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hhwk9k_rz02T","colab_type":"code","outputId":"5b6c5ab6-c8bc-47af-f637-378a9ac78776","executionInfo":{"status":"ok","timestamp":1550732303793,"user_tz":-120,"elapsed":184468,"user":{"displayName":"Moshe T","photoUrl":"","userId":"02650269545573136300"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["pretrained_embeddings = TEXT.vocab.vectors\n","\n","model.embedding.weight.data.copy_(pretrained_embeddings) #load pre train embeddings to emb' layer"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n","        ...,\n","        [ 0.1897, -0.0174,  0.6258,  ..., -0.3503,  0.0343,  0.8224],\n","        [-0.1428,  0.2808,  0.9812,  ..., -0.3610,  0.0521,  1.0778],\n","        [-0.2233, -0.0349,  0.7388,  ...,  0.1977, -0.1103,  0.0074]])"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"ebkF8b7o0HpJ","colab_type":"code","colab":{}},"source":["import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters()) #set optimizer do updtae parameters \n","#no need to set learning rate, ADAM also adepts learning rate for each parameter unlike SGD\n","\n","criterion = nn.BCEWithLogitsLoss() #define the loss function\n","\n","model = model.to(device) #load to GPU\n","criterion = criterion.to(device) #load to GPU"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uqdbLE2W0Kzd","colab_type":"code","colab":{}},"source":["def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds)) #squase [0,1] and round to close int\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum()/len(correct) #how many rounded prediction match the label avg accross a batch\n","    return acc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7gorVo6B0OBR","colab_type":"code","colab":{}},"source":["def train(model, iterator, optimizer, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train() #set to train mode, turns dropout on\n","    \n","    for batch in iterator:\n","        \n","        optimizer.zero_grad()#zero out grad att - pytorch does not do it auto' zero after the last calc'\n","        \n","        predictions = model(batch.text).squeeze(1) # set to 1 dim [batch size] for loss func\n","        \n","        loss = criterion(predictions, batch.label)\n","        \n","        acc = binary_accuracy(predictions, batch.label)\n","        \n","        loss.backward() #calculate grad for each param\n","        \n","        optimizer.step() #updaet param'\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator) #loss/accuracy avg' across the epoch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"il2Co9NE0RSS","colab_type":"code","colab":{}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.eval() #set to eval mode -turns dropout off\n","    \n","    with torch.no_grad(): #no grad calc' in this block -do not update on evaluation\n","    \n","        for batch in iterator:\n","\n","            predictions = model(batch.text).squeeze(1) # set to 1 dim [batch size] for loss func\n","            \n","            loss = criterion(predictions, batch.label)\n","            \n","            acc = binary_accuracy(predictions, batch.label)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FCfkoBQ-0UfM","colab_type":"code","outputId":"01a04fe0-a76f-4ad9-a2a9-8a932cbe458b","executionInfo":{"status":"ok","timestamp":1550732573286,"user_tz":-120,"elapsed":453918,"user":{"displayName":"Moshe T","photoUrl":"","userId":"02650269545573136300"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["N_EPOCHS = 5\n","train_losses = []\n","valid_losses = []\n","train_accuracy = []\n","valid_accuracy = []\n","\n","for epoch in range(N_EPOCHS):\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    train_accuracy.append(train_acc)\n","    valid_accuracy.append(valid_acc)\n","    \n","    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["| Epoch: 01 | Train Loss: 0.505 | Train Acc: 73.92% | Val. Loss: 0.337 | Val. Acc: 85.69% |\n","| Epoch: 02 | Train Loss: 0.310 | Train Acc: 87.20% | Val. Loss: 0.282 | Val. Acc: 88.18% |\n","| Epoch: 03 | Train Loss: 0.224 | Train Acc: 91.40% | Val. Loss: 0.267 | Val. Acc: 88.79% |\n","| Epoch: 04 | Train Loss: 0.148 | Train Acc: 94.66% | Val. Loss: 0.262 | Val. Acc: 89.68% |\n","| Epoch: 05 | Train Loss: 0.094 | Train Acc: 96.93% | Val. Loss: 0.281 | Val. Acc: 89.46% |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-XCsXQ8A1dQ-","colab_type":"code","outputId":"4b922d89-eb89-4655-ae81-f792ff736377","executionInfo":{"status":"ok","timestamp":1550737386314,"user_tz":-120,"elapsed":6184,"user":{"displayName":"Moshe T","photoUrl":"","userId":"02650269545573136300"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_loss, test_acc = evaluate(model, test_iterator, criterion)\n","\n","print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% |')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["| Test Loss: 0.308 | Test Acc: 88.14% |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1wVvIuin1kQb","colab_type":"code","colab":{}},"source":["import spacy\n","nlp = spacy.load('en')\n","\n","def predict_sentiment(sentence, min_len=5):\n","    tokenized = [tok.text for tok in nlp.tokenizer(sentence)] #tokanize raw input\n","    if len(tokenized) < min_len:\n","        tokenized += ['<pad>'] * (min_len - len(tokenized)) #input must be as long as largest filter -padding is applyied if not\n","    indexed = [TEXT.vocab.stoi[t] for t in tokenized] #convet to indexed representation of vocab\n","    tensor = torch.LongTensor(indexed).to(device) #list to tensor\n","    tensor = tensor.unsqueeze(1)#add batch dim\n","    prediction = torch.sigmoid(model(tensor)) #squash prediction value [0,1]\n","    return prediction.item() #covnert tensor holding a single value to int"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tIZljjj61sEZ","colab_type":"code","outputId":"c2c87e66-0ac2-4dbf-ba0c-2391d22abcce","executionInfo":{"status":"ok","timestamp":1550738566502,"user_tz":-120,"elapsed":520,"user":{"displayName":"Moshe T","photoUrl":"","userId":"02650269545573136300"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["predict_sentiment(\"I seen better movies\")"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4536677896976471"]},"metadata":{"tags":[]},"execution_count":56}]}]}