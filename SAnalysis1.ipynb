{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SAnalysis1.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"Oqk_aUWuFr2I","colab_type":"code","outputId":"1450cde3-f401-4bf4-eaa8-39b6c9722863","executionInfo":{"status":"ok","timestamp":1550129742767,"user_tz":-120,"elapsed":132755,"user":{"displayName":"Moshe T","photoUrl":"","userId":"02650269545573136300"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["import torch\n","from torchtext import data\n","from torchtext import datasets\n","import random\n","\n","SEED = 1234\n","\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","TEXT = data.Field(tokenize='spacy')\n","LABEL = data.LabelField(dtype=torch.float)\n","\n","train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n","\n","train_data, valid_data = train_data.split(random_state=random.seed(SEED))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["aclImdb_v1.tar.gz:   0%|          | 164k/84.1M [00:00<00:56, 1.47MB/s]"],"name":"stderr"},{"output_type":"stream","text":["downloading aclImdb_v1.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 56.2MB/s]\n"],"name":"stderr"}]},{"metadata":{"id":"Xubcco_uGuHL","colab_type":"code","outputId":"85f000ec-ef4c-4526-edf1-031081e6723b","executionInfo":{"status":"ok","timestamp":1550129902936,"user_tz":-120,"elapsed":292875,"user":{"displayName":"Moshe T","photoUrl":"","userId":"02650269545573136300"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["TEXT.build_vocab(train_data, max_size=25000, vectors=\"glove.6B.100d\")\n","LABEL.build_vocab(train_data)"],"execution_count":2,"outputs":[{"output_type":"stream","text":[".vector_cache/glove.6B.zip: 862MB [01:38, 8.74MB/s]                           \n","100%|█████████▉| 398524/400000 [00:17<00:00, 23367.38it/s]"],"name":"stderr"}]},{"metadata":{"id":"fB03NnFRHxvd","colab_type":"code","colab":{}},"cell_type":"code","source":["BATCH_SIZE = 64\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size=BATCH_SIZE, \n","    device=device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VvSAYmpMH8QB","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch.nn as nn\n","\n","class RNN(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n","        self.fc = nn.Linear(hidden_dim*2, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, x):\n","        \n","        #x = [sent len, batch size]\n","        \n","        embedded = self.dropout(self.embedding(x))\n","        \n","        #embedded = [sent len, batch size, emb dim]\n","        \n","        output, (hidden, cell) = self.rnn(embedded)\n","        \n","        #output = [sent len, batch size, hid dim * num directions]\n","        #hidden = [num layers * num directions, batch size, hid dim]\n","        #cell = [num layers * num directions, batch size, hid dim]\n","        \n","        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n","        #and apply dropout\n","        \n","        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n","                \n","        #hidden = [batch size, hid dim * num directions]\n","            \n","        return self.fc(hidden.squeeze(0))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_w1X_k42H_xz","colab_type":"code","colab":{}},"cell_type":"code","source":["INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","N_LAYERS = 2\n","BIDIRECTIONAL = True\n","DROPOUT = 0.5\n","\n","model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TUIb21IMIC_U","colab_type":"code","outputId":"205667c7-a1cb-473d-a826-ed609fb3b196","executionInfo":{"status":"ok","timestamp":1550130080795,"user_tz":-120,"elapsed":883,"user":{"displayName":"Moshe T","photoUrl":"","userId":"02650269545573136300"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["pretrained_embeddings = TEXT.vocab.vectors\n","\n","print(pretrained_embeddings.shape)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["torch.Size([25002, 100])\n"],"name":"stdout"}]},{"metadata":{"id":"RU0m_w0rIG5X","colab_type":"code","outputId":"d6bb6fc1-eec3-499b-8ff4-1dea9e391d3b","executionInfo":{"status":"ok","timestamp":1550130092254,"user_tz":-120,"elapsed":2013,"user":{"displayName":"Moshe T","photoUrl":"","userId":"02650269545573136300"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"cell_type":"code","source":["model.embedding.weight.data.copy_(pretrained_embeddings)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n","        ...,\n","        [-0.6242,  0.6298, -0.9362,  ..., -0.6600,  0.5187,  0.3486],\n","        [ 0.2566, -0.6234,  0.0901,  ..., -0.1434, -0.0360, -0.2209],\n","        [ 0.4260,  0.3201,  0.6102,  ...,  0.0601, -0.9927,  0.2160]])"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"id":"WAjeQzb1IJxB","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"l9TrwQixIL05","colab_type":"code","colab":{}},"cell_type":"code","source":["criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oAeindK1IN7U","colab_type":"code","colab":{}},"cell_type":"code","source":["def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum()/len(correct)\n","    return acc"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UZXRl0qkIQqE","colab_type":"code","colab":{}},"cell_type":"code","source":["def train(model, iterator, optimizer, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train()\n","    \n","    for batch in iterator:\n","        \n","        optimizer.zero_grad()\n","        \n","        predictions = model(batch.text).squeeze(1)\n","        \n","        loss = criterion(predictions, batch.label)\n","        \n","        acc = binary_accuracy(predictions, batch.label)\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6KPjGlO5IUEl","colab_type":"code","colab":{}},"cell_type":"code","source":["def evaluate(model, iterator, criterion):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.eval()\n","    \n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","\n","            predictions = model(batch.text).squeeze(1)\n","            \n","            loss = criterion(predictions, batch.label)\n","            \n","            acc = binary_accuracy(predictions, batch.label)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pvbNKOPPIZaT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":233},"outputId":"055d6ddd-65f2-4449-dac2-0d7b31165936","executionInfo":{"status":"error","timestamp":1550144775098,"user_tz":-120,"elapsed":1371,"user":{"displayName":"Moshe T","photoUrl":"","userId":"02650269545573136300"}}},"cell_type":"code","source":["N_EPOCHS = 5\n","\n","for epoch in range(N_EPOCHS):\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","    # Save a checkpoint\n","    checkpoint_filename = 'checkpoints/mnist-{:03d}.pkl'.format(epoch)\n","    save_checkpoint(optimizer, model, epoch, checkpoint_filename)\n","    \n","    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-edeeef206b70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Save a checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"]}]},{"metadata":{"id":"RrXIekAxErHk","colab_type":"code","colab":{}},"cell_type":"code","source":["def save_checkpoint(optimizer, model, epoch, filename):\n","    checkpoint_dict = {\n","        'optimizer': optimizer.state_dict(),\n","        'model': model.state_dict(),\n","        'epoch': epoch\n","    }\n","    torch.save(checkpoint_dict, filename)\n","\n","\n","def load_checkpoint(optimizer, model, filename):\n","    checkpoint_dict = torch.load(filename)\n","    epoch = checkpoint_dict['epoch']\n","    model.load_state_dict(checkpoint_dict['model'])\n","    if optimizer is not None:\n","        optimizer.load_state_dict(checkpoint_dict['optimizer'])\n","    return epoch"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3urtnbGRE9V1","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir -p checkpoints"],"execution_count":0,"outputs":[]}]}